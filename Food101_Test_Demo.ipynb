{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food 101 Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is BigBoy\n",
      " Volume Serial Number is 4813-32F9\n",
      "\n",
      " Directory of E:\\Data Science Playgrounds\\FoodHUD\n",
      "\n",
      "11/06/2017  05:52 PM    <DIR>          .\n",
      "11/06/2017  05:52 PM    <DIR>          ..\n",
      "11/06/2017  05:48 PM    <DIR>          .ipynb_checkpoints\n",
      "11/06/2017  05:48 PM    <DIR>          Data\n",
      "11/06/2017  05:52 PM             4,705 Food101_Test_Demo.ipynb\n",
      "               1 File(s)          4,705 bytes\n",
      "               4 Dir(s)  2,425,838,424,064 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import h5py\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"dir\", \"../Data/\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Data Science Playgrounds\\FoodHUD\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category', 'category_names', 'images']\n",
      "10099\n",
      "101\n",
      "10099\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#File Format\n",
    "#f=h5py.File('../input/food_c101_n1000_r384x384x3.h5','r')\n",
    "f=h5py.File('./Data/food_c101_n10099_r64x64x3.h5','r')\n",
    "print(list(f.keys()))\n",
    "print(len(f[\"category\"]))\n",
    "print(len(f[\"category_names\"]))\n",
    "print(len(f[\"images\"]))\n",
    "# Print Sample Pictures\n",
    "print([int(i) for i in f[\"category\"][0]])\n",
    "print(f[\"images\"][0].shape)\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "n=25\n",
    "col=5\n",
    "for i in range(n):\n",
    "    ax=fig.add_subplot(n/col,col,i+1)\n",
    "    #ax.set_title(f[\"category_names\"][i].decode())\n",
    "    ax.imshow(f[\"images\"][i])\n",
    "plt.savefig(\"./sample_show_64x64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "128/128 [==============================] - 29s 229ms/step - loss: 4.6151\n",
      "Epoch 2/5\n",
      "128/128 [==============================] - 26s 200ms/step - loss: 4.6129\n",
      "Epoch 3/5\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 4.6063\n",
      "Epoch 4/5\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 4.5882\n",
      "Epoch 5/5\n",
      "128/128 [==============================] - 26s 199ms/step - loss: 4.5483\n"
     ]
    }
   ],
   "source": [
    "#Keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers\n",
    "#model = ResNet50(weights=None,input_shape=(384,384,3),classes=101)\n",
    "model = VGG16(weights=None,input_shape=(64,64,3),classes=101)\n",
    "x=np.array(f[\"images\"])/255.\n",
    "y=np.array([[int(i) for i in f[\"category\"][j]] for j in range(len(f[\"category\"]))])\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=optimizers.rmsprop(lr=0.0001, decay=1e-6))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.00008, beta_1=0.9, beta_2=0.97, epsilon=1e-7))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train_x,test_x, train_y, test_y = train_test_split(x,y,test_size = 0.2)\n",
    "model.fit(train_x[:128],train_y[:128],batch_size=128,epochs=5,shuffle=False)\n",
    "#print(model.evaluate(test_x,test_y))\n",
    "test_x=train_x[:50]\n",
    "test_y=train_y[:50]\n",
    "pred_y=model.predict(test_x)\n",
    "zero_y=np.zeros(pred_y.shape)\n",
    "argmax_lst=np.argmax(pred_y,axis=1)\n",
    "for i in range(len(argmax_lst)):\n",
    "    zero_y[i][argmax_lst[i]]=1\n",
    "pred_y=zero_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc-Score: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"Acc-Score:\",accuracy_score(np.array(test_y),np.array(pred_y)))\n",
    "#print(\"F-score:\",f1_score(test_y,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
