<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">
  <head>
    <meta charset="UTF-8">

{% seo %}
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">
  </head>

  <body>

    <!-- Header section of the website -->
    <section class="page-header">
      <h1 class="project-name"><bold>FoodHUD</bold></h1>
      <h2 class="project-tagline">{{ site.description | default: site.github.project_tagline }}</h2>
      {% if site.github.is_project_page %}
        <a href="{{ site.github.repository_url }}" class="btn">View on GitHub</a>
      {% endif %}
      {% if site.show_downloads %}
        <a href="{{ site.github.zip_url }}" class="btn">Download .zip</a>
        <a href="{{ site.github.tar_url }}" class="btn">Download .tar.gz</a>
      {% endif %}
    </section>

    <!-- This adds a sidebar menu for easy jumping around
    <div class="w3-sidebar w3-bar-block" style="width:225px;" id="mySidebar">
      <h3 class="w3-bar-item">Menu</h3>
      <a href="#topic1" class="w3-bar-item w3-button">What is FoodHUD?</a>
      <a href="#topic2" class="w3-bar-item w3-button">Background Motivation</a>
      <div class="w3-dropdown-hover">
        <button class="w3-button">How We Made FoodHUD <i class="fa fa-caret-down"></i></button>
        <div class="w3-dropdown-content w3-bar-block">
            <a href="#topic3_1" class="w3-bar-item w3-button">Image Data</a>
            <a href="#topic3_2" class="w3-bar-item w3-button">Nutritional Data</a>
            <a href="#topic3_3" class="w3-bar-item w3-button">Modeling</a>
            <a href="#topic3_4" class="w3-bar-item w3-button">Web Application</a>
        </div>
      </div>
      <a href="#topic4" class="w3-bar-item w3-button">Resources</a>
    </div>
    -->


    <!-- Side bar that can open and close
    <div class="w3-sidebar w3-border-right w3-bar-block w3-animate-left" style="display:none" id="mySidebar">
      <button class="w3-bar-item w3-button w3-large"
      onclick="w3_close()">Close &times;</button> -->
    <div id="mySidenav" class="sidenav">
      <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
      <a href="#topic1">What is FoodHUD?</a>
      <a href="#topic2">Background motivation</a>
      <a href="#topic3">How we made FoodHUD</a>
      <a href="#topic4">Resources</a>
    </div>

    <!-- Use any element to open the sidenav -->
    <button class="openNav" onclick="openNav()">&#9776;</button>

    <div id="main">

    <!-- Large banner below hero image
    <div class="w3-teal">
      <button id="openNav" class="w3-button w3-teal w3-xlarge" onclick="w3_open()">&#9776;</button>
      <div class="w3-container">
        <h1>My Page</h1>
      </div>
    </div> -->

    <!-- Main text of site is here -->
    <section class="main-content">

      <h2 id="topic1"> What is FoodHUD? </h2>
      <p>FoodHUD is an easy to use web application where a user uploads an image of food and then receives the name of the food along with nutritional data on the food.</p>

      <h2 id="topic2"> Background motivation </h2>

      <p>Millions of Americans struggle with their weight and its effects on their physical health.
        Portion control can be a serious challenge for busy people,
        and often it is difficult for someone to estimate the caloric content of a given meal.
        While a human may struggle with the task,
        a well-trained machine may not. </p>

        <img src="obesity.jpg">

      <p>Recent advances in computer vision, driven by developments in deep learning,
        have enabled computers to successfully distinguish thousands of classes of images of items with impressive accuracy.
        Researchers have already developed image classification data sets comprised of images of food.</p>
      <p>One such data set, Food101, contains 101 classes of food with 1000 high-resolution images for each class.
        Several well-established baselines exist for Food101, including relatively performant deep learning solutions.
        This provides a proof of concept that the automated identification of food is within our grasp,
        and these solutions may provide a path forward for Americans seeking to reign in their caloric intake.</p>

      <h2 id="topic3"> How we made FoodHUD </h2>

      <p>Inspired by the progress made on the Food101 data set,
        we set out to implement an automated tool to estimate the caloric content of a plate of food based on an image.
        We believe that such a product, available as a web-based application or preferably a mobile application,
        could bolster a consumer’s ability to control their diet and be more health- and nutrition-conscious. </p>

      <p>We developed our solution in multiple parallel stages.
        We knew that we needed to acquire not only labelled image data of foods,
        but also coinciding nutritional data on those same foods.
        We have already discussed Food101 as a data source,
        but we explored additional options to augment this source with more images.
        Knowing that we would need to integrate caloric data at a minimum,
        we search for and evaluated a few different sources of nutritional information.
        We chose to update the neural network architecture to reflect our augmented data set.
        Finally, we needed to create an application to leverage our deep learning model and perform class identification and use a lookup table to derive calorie prediction.</p>

      <h3 id="topic3_1"> Image Set Augmentation </h3>
      <p>The pre-existing Food101 dataset offered a laudable 1000 images per class,
        we suspected that we would benefit from an augmented data set (e.g. more images, more classes).
        To that end, we explored a few additional data sources,
        including pre-compiled data sets and public image sites.
        Namely, we considered integrating data from the UEC data set,
        which could have supplied more images and additional classes for us.
        However, these classes seemed skewed toward Japanese cuisine,
        which would have been less beneficial for a typical American dieter.</p>
      <p>We also attempted to scrape images from Google Images, Instagram, and Flickr.
        We found a useful Chrome extension for Google Images, but the daily throughput was limited.
        Because of this, it would have taken a long time to acquire an image set even comparable to Food101.
        MORE STUFF ABOUT INSTAGRAM AND FLICKR!!!! ADDDDDD HEEEREE</p>
      <p>Ultimately, we decided that automated data augmentation of our existing image set was the best path forward for us.
        This would allow us to expand our image set from the existing Food101 data set without worrying about data quality and accuracy.
        Therefore, we produced 10 images from every 1 original image in Food101,
        taking 5 different crops of the image in its original orientation and also its reflection about its vertical axis.
        This expanded image set proved to improve our performance over the baseline, and so we were satisfied with it.</p>

      <h3 id="topic3_2"> Nutritional Information Acquisition </h3>
      <p>Because we wanted to predict calorie data about a food, we needed a reliable and open resource for nutritional information.
        Initially, we sought to use MyFitnessPal as a data source. It seemed like a reliable data source,
        and all of the Food101 categories had at least one relevant entry in the nutritional database.
        However, due to MyFitnessPal’s policy against automated collection of data, we chose to collect it by hand,
        which was cumbersome. Because of this, we only took one data point for each category,
        which resulted in quite a few categories that had anomalous calorie values.
        These anomalies, as well as the fact that MyFitnessPal is not a truly open resource,
        led us to discard MyFitnessPal as a data source.</p>
      <p>Fortunately, we found a reasonable public data source in the USDA National Nutrient Database for Standard Reference.
        This provides nutrient data about nearly 9000 foods, many of which overlap with the food categories in Food101.
        Using the caloric information from this data source, we were able to compute the median caloric density (kcal/100g) for 53 of the original 101 food categories in Food101.
        These calorie values seem reasonable and will allow us to integrate nutritional data into our application.</p>



      <p>The distributions seem to suggest that MyFitnessPal's "per serving" calorie values and USDA's "per 100grams" calorie values are similar. However there are a couple issues.</p>

      <p>First, here we see that there are some issues with the calorie values for foods in MyFitnessPal:</p>
      <img src="mfp_hist.png">

      <p>Compared to the relatively stable distribution found from USDA:</p>
      <img src="usda_hist.png">

      <p>Second, we fail to see a linear relationship between "per serving" and "caloric density" in the data plotted here:</p>
      <img src="calorie_comparison.png">



      <h3 id="topic3_3"> Modeling </h3>
      <h4> Classification Modeling </h4>
      <p> I don't know what we'll say here, if anything. </p>

      <h4> Regression Modeling </h4>
      <p>Our final architecture used classification and then looked up the median caloric density based on the class.
        However, we were also interested in determining the performance of the model when attempting to use linear regression to predict the caloric density directly.
        We ran an experiment with a subset of 1000 of the Food101 images,
        filtering down to those images belonging to the 53 classes for which we had caloric densities.
        Then, resizing the images, we collected features for each image from the Keras application for the VGG16 network trained on ImageNet.
        We then fed these features into a PCA with a number of principal components varying from 1 to 100 and used a 5-fold cross-validation to compute a mean squared error.
        We used a much simpler model as our baseline, whose only input features were the sums across all pixels of each of the three color channels.
        This three-feature model performed comparably with models trained on the PCA transformation of the extracted image features, which suggests that,
        at the very least, linear regression is not a reasonable option for direct regression of caloric density.</p>

        <img src="cheesecake_regress.png">
        <img src="macaron_regress.png">

      <h3 id="topic3_4"> Web-Based Application </h3>
      <p>Using Python's Flask library and Google's Cloud services, we established a web application capable of serving Keras model predictions based on user provided contet. </p>


      <h2 id="topic4"> Resources </h2>
      <ol>
          <li>First resource</li>
          <li>Second resource</li>
          <li>Third resource</li>
      </ol>
      <!-- use this if you want to use README.md as main html page text instead
      {{ content }}
      -->

      <!-- Footer section of site here -->
      <footer class="site-footer">
        {% if site.github.is_project_page %}
        <span class="site-footer-owner"> UC, Berkeley MIDS Fall 2017 </span>
          <!-- <span class="site-footer-owner"><a href="{{ site.github.repository_url }}">{{ site.github.repository_name }}</a> is maintained by <a href="{{ site.github.owner_url }}">{{ site.github.owner_name }}</a>.</span>-->
        {% endif %}
        <p> This is some other publishing info </p>
        <!--<span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>-->
      </footer>
    </section>
    </div>

    <!-- Trying to get menu button to stay still... might not need this
    window.onscroll = function() {scrollFunction()};

    function scrollFunction() {
        if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
            document.getElementByClassName("openNav")[0].style.display = "block";
    }
    -->

    <script>
      /* Set the width of the side navigation to 250px and the left margin of the page content to 250px */
      function openNav() {
          document.getElementById("mySidenav").style.width = "250px";
          document.getElementById("main").style.marginLeft = "250px";
      }

      /* Set the width of the side navigation to 0 and the left margin of the page content to 0 */
      function closeNav() {
          document.getElementById("mySidenav").style.width = "0";
          document.getElementById("main").style.marginLeft = "0";
      }
    </script>
    {% if site.google_analytics %}
      <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', '{{ site.google_analytics }}', 'auto');
        ga('send', 'pageview');
      </script>
    {% endif %}
  </body>
</html>
